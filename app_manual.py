# app_manual.py (ìµœì¢… í´ë¼ìš°ë“œ ë°°í¬ ë²„ì „)

import streamlit as st
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import json
import openai
import os

st.set_page_config(page_title="AI ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ ì±—ë´‡", page_icon="ğŸ“š", layout="centered")

# --- API í‚¤ ì„¤ì • (Streamlitì˜ Secrets ê´€ë¦¬ ê¸°ëŠ¥ ì‚¬ìš©) ---
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except Exception as e:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì— í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")


# --- ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© (ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”) ---
@st.cache_resource
def load_models_and_data():
    """ì‚¬ì „ì— ì¤€ë¹„ëœ ë°ì´í„° íŒŒì¼ê³¼, ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # ======================================================================
        # ## ëª¨ë¸ ë¡œë“œ ë°©ì‹ ë³€ê²½ ##
        # ë¡œì»¬ ê²½ë¡œ ëŒ€ì‹ , í—ˆê¹…í˜ì´ìŠ¤ ì¸í„°ë„· ì£¼ì†Œë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # Streamlit Cloud ì„œë²„ê°€ ì´ ëª¨ë¸ì„ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•  ê²ƒì…ë‹ˆë‹¤.
        model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        # ======================================================================
        
        index = faiss.read_index("manuals_vector_db.index")
        with open("all_manual_chunks.json", "r", encoding="utf-8") as f:
            chunks_with_metadata = json.load(f)
        return model, index, chunks_with_metadata
    except FileNotFoundError:
        return None, None, None

def get_relevant_manual_chunks(user_question, k=5):
    question_vector = model.encode([user_question])
    distances, indices = index.search(np.array(question_vector, dtype=np.float32), k)
    relevant_chunks = [chunks_with_metadata[i] for i in indices[0]]
    return relevant_chunks

def generate_answer_with_llm(user_question, relevant_chunks):
    context_str = ""
    for chunk in relevant_chunks:
        context_str += f"ì¶œì²˜: {chunk['source']}\në‚´ìš©: {chunk['content']}\n\n"
    
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì œê³µëœ ì‚¬ë‚´ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì£¼ì–´ì§„ [ê´€ë ¨ ë§¤ë‰´ì–¼ ì •ë³´] ë‚´ì—ì„œë§Œ ë‹µë³€í•˜ê³ , ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
        {"role": "user", "content": f"[ê´€ë ¨ ë§¤ë‰´ì–¼ ì •ë³´]\n{context_str}\n---\n[ì§ˆë¬¸]\n{user_question}"}
    ]
    
    try:
        response = openai.chat.completions.create(model="gpt-4o", messages=messages, temperature=0.7)
        return response.choices[0].message.content
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

st.title("ğŸ“š AI ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ ì±—ë´‡")
model, index, chunks_with_metadata = load_models_and_data()

if model is None:
    st.error("ì±—ë´‡ ë°ì´í„° íŒŒì¼('manuals_vector_db.index' ë˜ëŠ” 'all_manual_chunks.json')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.success("ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!", icon="âœ…")
    st.markdown("íšŒì‚¬ ë‚´ë¶€ ë§¤ë‰´ì–¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    user_question = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì˜ˆ: ì‹ ê·œ ì…ì‚¬ì ë…¸íŠ¸ë¶ ì‹ ì²­ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")
    if st.button("ì§ˆë¬¸í•˜ê¸°", type="primary"):
        if user_question:
            with st.spinner("AIê°€ ë§¤ë‰´ì–¼ì„ ê²€í† í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                relevant_chunks = get_relevant_manual_chunks(user_question)
                answer = generate_answer_with_llm(user_question, relevant_chunks)
                st.markdown("#### ğŸ’¬ AI ë‹µë³€")
                st.write(answer)
                st.markdown("---")
                with st.expander("AIê°€ ì°¸ê³ í•œ ë§¤ë‰´ì–¼ ë‚´ìš© ë³´ê¸°"):
                    sources = sorted(list(set([chunk['source'] for chunk in relevant_chunks])))
                    st.markdown(f"**ì°¸ê³  ë§¤ë‰´ì–¼:** {', '.join(sources)}")
                    st.json(relevant_chunks)
        else:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.divider()
    st.caption("ì£¼ì˜: ì´ ì±—ë´‡ì˜ ë‹µë³€ì€ ì°¸ê³ ìš©ì´ë©°, ìµœì¢… í™•ì¸ì€ ê³µì‹ ë¬¸ì„œë¥¼ í†µí•´ ì§„í–‰í•´ì£¼ì„¸ìš”.")
