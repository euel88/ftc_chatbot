# íŒŒì¼ ì´ë¦„: app_manual.py (ê°œì„ ëœ ê³µì •ê±°ë˜ìœ„ì›íšŒ AI ë²•ë¥  ë³´ì¡°ì›)

import streamlit as st
import faiss
from sentence_transformers import SentenceTransformer, CrossEncoder
import json
import openai
import numpy as np
from typing import List, Dict, Tuple, Optional, Set
import re
from collections import defaultdict, Counter
import time
from dataclasses import dataclass
import os

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ì „ëµê¸°íšë¶€ AI ë²•ë¥  ë³´ì¡°ì›", 
    page_icon="âš–ï¸", 
    layout="wide",
    initial_sidebar_state="collapsed"  # ì‚¬ì´ë“œë°” ê¸°ë³¸ ìˆ¨ê¹€
)

# ê¹”ë”í•œ UIë¥¼ ìœ„í•œ CSS
st.markdown("""
<style>
    /* ë¶ˆí•„ìš”í•œ Streamlit ê¸°ë³¸ ìš”ì†Œ ìˆ¨ê¸°ê¸° */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* ë©”ì¸ í—¤ë” ìŠ¤íƒ€ì¼ */
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #1f4788 0%, #2a5298 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    
    .chat-container {
        max-width: 800px;
        margin: 0 auto;
    }
    
    /* ëŒ€í™” ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stChatMessage {
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    
    /* ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ ê°œì„  */
    .stSpinner > div {
        text-align: center;
        color: #1f4788;
    }
</style>
""", unsafe_allow_html=True)

# OpenAI API ì„¤ì •
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except:
    st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 2. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ê¸° ---
class QuestionClassifier:
    """ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë§¤ë‰´ì–¼ì„ ìš°ì„  ê²€ìƒ‰í• ì§€ ê²°ì •"""
    
    def __init__(self):
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í•µì‹¬ í‚¤ì›Œë“œ
        self.categories = {
            'ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜': {
                'keywords': ['ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜', 'ë‚´ë¶€ê±°ë˜', 'ì´ì‚¬íšŒ ì˜ê²°', 'ì´ì‚¬íšŒ', 'ì˜ê²°', 
                           'ê³„ì—´ì‚¬', 'ê³„ì—´íšŒì‚¬', 'íŠ¹ìˆ˜ê´€ê³„ì¸', 'ìê¸ˆ', 'ëŒ€ì—¬', 'ì°¨ì…', 'ë³´ì¦'],
                'manual_pattern': 'ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜.*ë§¤ë‰´ì–¼',
                'priority': 1
            },
            'í˜„í™©ê³µì‹œ': {
                'keywords': ['í˜„í™©ê³µì‹œ', 'ê¸°ì—…ì§‘ë‹¨', 'ì†Œì†íšŒì‚¬', 'ë™ì¼ì¸', 'ì¹œì¡±', 
                           'ì§€ë¶„ìœ¨', 'ì„ì›', 'ìˆœí™˜ì¶œì', 'ìƒí˜¸ì¶œì'],
                'manual_pattern': 'ê¸°ì—…ì§‘ë‹¨í˜„í™©ê³µì‹œ.*ë§¤ë‰´ì–¼',
                'priority': 2
            },
            'ë¹„ìƒì¥ì‚¬ ì¤‘ìš”ì‚¬í•­': {
                'keywords': ['ë¹„ìƒì¥', 'ì¤‘ìš”ì‚¬í•­', 'ì£¼ì‹', 'ì–‘ë„', 'ì–‘ìˆ˜', 'í•©ë³‘', 
                           'ë¶„í• ', 'ì˜ì—…ì–‘ë„', 'ì„ì›ë³€ê²½'],
                'manual_pattern': 'ë¹„ìƒì¥ì‚¬.*ì¤‘ìš”ì‚¬í•­.*ë§¤ë‰´ì–¼',
                'priority': 3
            }
        }
    
    def classify(self, question: str) -> Tuple[str, float]:
        """ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ê³  ì‹ ë¢°ë„ë¥¼ ë°˜í™˜"""
        question_lower = question.lower()
        scores = {}
        
        for category, info in self.categories.items():
            score = 0
            matched_keywords = []
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in info['keywords']:
                if keyword in question_lower:
                    score += 1
                    matched_keywords.append(keyword)
            
            # ê°€ì¤‘ì¹˜ ì ìš© (ì²˜ìŒ 3ê°œ í‚¤ì›Œë“œëŠ” ë” ë†’ì€ ì ìˆ˜)
            if matched_keywords:
                primary_keywords = info['keywords'][:3]
                for kw in matched_keywords:
                    if kw in primary_keywords:
                        score += 0.5
            
            scores[category] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        if scores:
            best_category = max(scores, key=scores.get)
            confidence = scores[best_category] / max(len(info['keywords']) for info in self.categories.values())
            
            # ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ None ë°˜í™˜
            if confidence < 0.1:
                return None, 0.0
                
            return best_category, confidence
        
        return None, 0.0

# --- 3. ê°œì„ ëœ ê²€ìƒ‰ ì‹œìŠ¤í…œ ---
@dataclass
class SearchResult:
    chunk_id: str
    content: str
    score: float
    source: str
    page: int
    chunk_type: str
    metadata: Dict

class OptimizedRAGPipeline:
    """ì†ë„ì™€ ì •í™•ë„ë¥¼ ê°œì„ í•œ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, embedding_model, reranker_model, index, chunks):
        self.embedding_model = embedding_model
        self.reranker_model = reranker_model
        self.index = index
        self.chunks = chunks
        self.classifier = QuestionClassifier()
        
        # ë§¤ë‰´ì–¼ë³„ ì²­í¬ ì¸ë±ìŠ¤ ë¯¸ë¦¬ ìƒì„± (ë¹ ë¥¸ í•„í„°ë§)
        self.manual_indices = self._build_manual_indices()
    
    def _build_manual_indices(self) -> Dict[str, List[int]]:
        """ê° ë§¤ë‰´ì–¼ë³„ë¡œ ì²­í¬ ì¸ë±ìŠ¤ë¥¼ ë¯¸ë¦¬ êµ¬ì¶•"""
        indices = defaultdict(list)
        
        for idx, chunk in enumerate(self.chunks):
            source = chunk.get('source', '').lower()
            
            # ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜ ë§¤ë‰´ì–¼
            if 'ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜' in source:
                indices['ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜'].append(idx)
            # í˜„í™©ê³µì‹œ ë§¤ë‰´ì–¼  
            elif 'í˜„í™©ê³µì‹œ' in source or 'ê¸°ì—…ì§‘ë‹¨' in source:
                indices['í˜„í™©ê³µì‹œ'].append(idx)
            # ë¹„ìƒì¥ì‚¬ ë§¤ë‰´ì–¼
            elif 'ë¹„ìƒì¥' in source:
                indices['ë¹„ìƒì¥ì‚¬ ì¤‘ìš”ì‚¬í•­'].append(idx)
            # ê¸°íƒ€
            else:
                indices['ê¸°íƒ€'].append(idx)
        
        return dict(indices)
    
    def search(self, query: str, top_k: int = 5) -> Tuple[List[SearchResult], Dict]:
        """ê°œì„ ëœ ê²€ìƒ‰: ì¹´í…Œê³ ë¦¬ë³„ ìš°ì„ ìˆœìœ„ ì ìš©"""
        start_time = time.time()
        
        # 1. ì§ˆë¬¸ ë¶„ë¥˜
        category, confidence = self.classifier.classify(query)
        
        # 2. ê²€ìƒ‰ ì „ëµ ê²°ì •
        if category and confidence > 0.3:
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë§¤ë‰´ì–¼ ìš°ì„  ê²€ìƒ‰
            search_strategy = 'targeted'
            primary_indices = self.manual_indices.get(category, [])
            secondary_indices = []
            
            # ë‚˜ë¨¸ì§€ ì¸ë±ìŠ¤ë„ í¬í•¨ (ë‚®ì€ ìš°ì„ ìˆœìœ„)
            for cat, indices in self.manual_indices.items():
                if cat != category:
                    secondary_indices.extend(indices)
        else:
            # ì „ì²´ ê²€ìƒ‰
            search_strategy = 'general'
            primary_indices = list(range(len(self.chunks)))
            secondary_indices = []
        
        # 3. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        results = self._perform_search(
            query, 
            primary_indices, 
            secondary_indices,
            top_k
        )
        
        # 4. í†µê³„ ìƒì„±
        stats = {
            'category': category,
            'confidence': confidence,
            'strategy': search_strategy,
            'search_time': time.time() - start_time,
            'primary_searched': len(primary_indices),
            'total_chunks': len(self.chunks)
        }
        
        return results, stats
    
    def _perform_search(self, query: str, primary_indices: List[int], 
                       secondary_indices: List[int], top_k: int) -> List[SearchResult]:
        """ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ (ê°œì„ ëœ ì†ë„)"""
        # ì¿¼ë¦¬ ë²¡í„° ìƒì„±
        query_vector = self.embedding_model.encode([query])
        
        # ìš°ì„ ìˆœìœ„ ì²­í¬ë§Œìœ¼ë¡œ ì œí•œëœ ê²€ìƒ‰
        if primary_indices:
            # FAISS ì„œë¸Œ ì¸ë±ìŠ¤ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            primary_chunks = [self.chunks[i] for i in primary_indices]
            primary_vectors = []
            
            for chunk in primary_chunks:
                # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ë²¡í„° ì¬ì‚¬ìš© (ì†ë„ ê°œì„ )
                text = chunk['content'][:500]  # ì²˜ìŒ 500ìë§Œ ì‚¬ìš©
                vec = self.embedding_model.encode([text])
                primary_vectors.append(vec[0])
            
            # ë¹ ë¥¸ ê²€ìƒ‰
            primary_vectors = np.array(primary_vectors, dtype=np.float32)
            distances = np.dot(query_vector[0], primary_vectors.T)
            top_indices = np.argsort(distances)[-top_k:][::-1]
            
            # ê²°ê³¼ ìƒì„±
            results = []
            for idx in top_indices:
                original_idx = primary_indices[idx]
                chunk = self.chunks[original_idx]
                
                result = SearchResult(
                    chunk_id=chunk.get('chunk_id', str(original_idx)),
                    content=chunk['content'],
                    score=float(distances[idx]),
                    source=chunk['source'],
                    page=chunk['page'],
                    chunk_type=chunk.get('chunk_type', 'unknown'),
                    metadata=json.loads(chunk.get('metadata', '{}'))
                )
                results.append(result)
            
            return results
        
        # í´ë°±: ì „ì²´ ê²€ìƒ‰
        return self._full_search(query_vector, top_k)
    
    def _full_search(self, query_vector, top_k: int) -> List[SearchResult]:
        """ì „ì²´ ì¸ë±ìŠ¤ ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹)"""
        scores, indices = self.index.search(query_vector, top_k * 2)
        
        results = []
        for idx, score in zip(indices[0], scores[0]):
            if idx < len(self.chunks):
                chunk = self.chunks[idx]
                result = SearchResult(
                    chunk_id=chunk.get('chunk_id', str(idx)),
                    content=chunk['content'],
                    score=float(score),
                    source=chunk['source'],
                    page=chunk['page'],
                    chunk_type=chunk.get('chunk_type', 'unknown'),
                    metadata=json.loads(chunk.get('metadata', '{}'))
                )
                results.append(result)
        
        return results[:top_k]

# --- 4. ëª¨ë¸ ë¡œë”© (ê°„ì†Œí™”) ---
@st.cache_resource(show_spinner=False)
def load_models_and_data():
    """í•„ìš”í•œ ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ"""
    try:
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        required_files = ["manuals_vector_db.index", "all_manual_chunks.json"]
        for file in required_files:
            if not os.path.exists(file):
                st.error(f"âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file}")
                st.info("ğŸ’¡ prepare_pdfs_ftc.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                return None, None, None, None
        
        # ë°ì´í„° ë¡œë“œ
        index = faiss.read_index("manuals_vector_db.index")
        with open("all_manual_chunks.json", "r", encoding="utf-8") as f:
            chunks = json.load(f)
        
        # ëª¨ë¸ ë¡œë“œ (ì‹¬í”Œí•˜ê²Œ)
        with st.spinner("AI ì‹œìŠ¤í…œì„ ì¤€ë¹„í•˜ëŠ” ì¤‘... (ìµœì´ˆ 1íšŒë§Œ ìˆ˜í–‰)"):
            # ì„ë² ë”© ëª¨ë¸
            try:
                # ì˜¨ë¼ì¸ ëª¨ë¸ ì‹œë„
                embedding_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
            except:
                # ëŒ€ì²´ ëª¨ë¸
                embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            
            # ì¬ì •ë ¬ ëª¨ë¸
            try:
                reranker_model = CrossEncoder('Dongjin-kr/ko-reranker')
            except:
                reranker_model = None  # ì¬ì •ë ¬ ì—†ì´ë„ ì‘ë™ ê°€ëŠ¥
        
        return embedding_model, reranker_model, index, chunks
        
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

# --- 5. ë‹µë³€ ìƒì„± (ê°„ì†Œí™”) ---
def generate_answer(query: str, results: List[SearchResult], category: str = None) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    for i, result in enumerate(results[:5]):  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
        context_parts.append(f"""
[ì°¸ê³  {i+1}] {result.source} (p.{result.page})
{result.content}
""")
    
    context = "\n---\n".join(context_parts)
    
    # ì§ˆë¬¸ ìœ í˜• ë¶„ì„ (temperature ì¡°ì •ìš©)
    def determine_temperature(query: str) -> float:
        """ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìµœì ì˜ temperature ê²°ì •"""
        query_lower = query.lower()
        
        # ë‹¨ìˆœ ì‚¬ì‹¤ í™•ì¸ ì§ˆë¬¸ (ë‚®ì€ temperature)
        if any(keyword in query_lower for keyword in ['ì–¸ì œ', 'ë©°ì¹ ', 'ê¸°í•œ', 'ê¸ˆì•¡', 'í¼ì„¼íŠ¸', '%']):
            return 0.1
        
        # ì •ì˜ë‚˜ ë²”ìœ„ ì§ˆë¬¸ (ì¤‘ê°„ temperature)
        elif any(keyword in query_lower for keyword in ['ì •ì˜', 'ë²”ìœ„', 'í¬í•¨', 'í•´ë‹¹', 'ëŒ€ìƒ']):
            return 0.3
        
        # ë³µì¡í•œ ìƒí™© íŒë‹¨ ì§ˆë¬¸ (ë†’ì€ temperature)
        elif any(keyword in query_lower for keyword in ['ì–´ë–»ê²Œ', 'ê²½ìš°', 'ë§Œì•½', 'ì˜ˆì™¸', 'ê°€ëŠ¥', 'ë°©ë²•']):
            return 0.5
        
        # ì „ëµì  ìë¬¸ ì§ˆë¬¸ (ë” ë†’ì€ temperature)
        elif any(keyword in query_lower for keyword in ['ì „ëµ', 'ëŒ€ì‘', 'ë¦¬ìŠ¤í¬', 'ì£¼ì˜ì‚¬í•­', 'ê³ ë ¤ì‚¬í•­']):
            return 0.7
        
        # ê¸°ë³¸ê°’
        else:
            return 0.3
    
    # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ì§€ì‹œì‚¬í•­
    category_instructions = {
        'ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜': "ì´ì‚¬íšŒ ì˜ê²° ìš”ê±´, ê³µì‹œ ê¸°í•œ, ì˜ˆì™¸ì‚¬í•­ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
        'í˜„í™©ê³µì‹œ': "ê³µì‹œ ì£¼ì²´, ê³µì‹œ ì‹œê¸°, ì œì¶œ ì„œë¥˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
        'ë¹„ìƒì¥ì‚¬ ì¤‘ìš”ì‚¬í•­': "ê³µì‹œ ëŒ€ìƒ ê±°ë˜, ê³µì‹œ ê¸°í•œ, ì œì¶œ ë°©ë²•ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”."
    }
    
    extra_instruction = category_instructions.get(category, "") if category else ""
    
    # Temperature ê²°ì •
    optimal_temperature = determine_temperature(query)
    
    # í”„ë¡¬í”„íŠ¸ (temperatureì— ë”°ë¼ ì§€ì‹œì‚¬í•­ ì¡°ì •)
    system_content = """ë‹¹ì‹ ì€ ê³µì •ê±°ë˜ìœ„ì›íšŒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ìë£Œë§Œì„ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ì‹¤ë¬´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ì‘ì„±í•˜ë©°, ê·¼ê±° ì¡°í•­ì´ë‚˜ í˜ì´ì§€ë¥¼ ëª…ì‹œí•˜ì„¸ìš”."""
    
    # ë†’ì€ temperatureì¼ ë•ŒëŠ” ë” ê¹Šì€ ë¶„ì„ ìš”ì²­
    if optimal_temperature >= 0.5:
        system_content += "\në‹¤ì–‘í•œ ê´€ì ê³¼ ì‹¤ë¬´ì  ê³ ë ¤ì‚¬í•­ì„ í¬í•¨í•˜ì—¬ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
    
    messages = [
        {
            "role": "system", 
            "content": system_content
        },
        {
            "role": "user",
            "content": f"""ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì°¸ê³  ìë£Œ]
{context}

[ì§ˆë¬¸]
{query}

{extra_instruction}

{"ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ" if optimal_temperature < 0.3 else "ìƒì„¸í•˜ê³  ì‹¤ë¬´ì ìœ¼ë¡œ"} ë‹µë³€í•´ì£¼ì„¸ìš”."""
        }
    ]
    
    # GPT í˜¸ì¶œ (ë™ì  temperature ì ìš©)
    response = openai.chat.completions.create(
        model="gpt-4o",  # GPT-4o ëª¨ë¸ ì‚¬ìš© (ë” ì •í™•í•œ ë‹µë³€)
        messages=messages,
        temperature=optimal_temperature,
        max_tokens=1000
    )
    
    return response.choices[0].message.content

# --- 6. ë©”ì¸ UI ---
def main():
    # í—¤ë” (ê°„ë‹¨í•˜ê²Œ)
    st.markdown("""
    <div class="main-header">
        <h1>âš–ï¸ ì „ëµê¸°íšë¶€ AI ë²•ë¥  ë³´ì¡°ì›</h1>
        <p style="margin: 0; opacity: 0.9;">ê³µì •ê±°ë˜ìœ„ì›íšŒ ê·œì • ë° ë§¤ë‰´ì–¼ ê¸°ë°˜ Q&A ì‹œìŠ¤í…œ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ëª¨ë¸ ë¡œë“œ
    models = load_models_and_data()
    if not all(models):
        st.stop()
    
    embedding_model, reranker_model, index, chunks = models
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = OptimizedRAGPipeline(embedding_model, reranker_model, index, chunks)
    
    # ì„¸ì…˜ ìƒíƒœ
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ëŒ€í™” ì˜ì—­
    chat_container = st.container()
    
    with chat_container:
        # ì´ì „ ëŒ€í™” í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "user":
                    st.write(message["content"])
                else:
                    # assistant ë©”ì‹œì§€ ì²˜ë¦¬
                    if isinstance(message["content"], dict):
                        # ìƒˆë¡œìš´ í˜•ì‹ (ì‹œê°„ ì •ë³´ í¬í•¨)
                        st.write(message["content"]["content"])
                        
                        # ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                        if "total_time" in message["content"]:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ğŸ” ê²€ìƒ‰", f"{message['content']['search_time']:.1f}ì´ˆ")
                            with col2:
                                st.metric("âœï¸ ë‹µë³€ ìƒì„±", f"{message['content']['generation_time']:.1f}ì´ˆ")
                            with col3:
                                st.metric("â±ï¸ ì „ì²´", f"{message['content']['total_time']:.1f}ì´ˆ")
                    else:
                        # ì´ì „ í˜•ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
                        st.write(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜ ê³µì‹œ ê¸°í•œì€?)"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
            
            # AI ì‘ë‹µ
            with st.chat_message("assistant"):
                # ì „ì²´ ì‹œê°„ ì¸¡ì • ì‹œì‘
                total_start_time = time.time()
                
                # ê²€ìƒ‰ ìˆ˜í–‰
                search_start_time = time.time()
                with st.spinner("ê´€ë ¨ ìë£Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                    results, stats = rag.search(prompt, top_k=5)
                search_time = time.time() - search_start_time
                
                # ë‹µë³€ ìƒì„±
                generation_start_time = time.time()
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    answer = generate_answer(prompt, results, stats.get('category'))
                generation_time = time.time() - generation_start_time
                
                # ì „ì²´ ì‹œê°„ ê³„ì‚°
                total_time = time.time() - total_start_time
                
                # ë‹µë³€ í‘œì‹œ
                st.write(answer)
                
                # ì‹œê°„ ì •ë³´ í‘œì‹œ (ì‘ì€ ë©”íŠ¸ë¦­ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ)
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ” ê²€ìƒ‰", f"{search_time:.1f}ì´ˆ")
                with col2:
                    st.metric("âœï¸ ë‹µë³€ ìƒì„±", f"{generation_time:.1f}ì´ˆ")
                with col3:
                    st.metric("â±ï¸ ì „ì²´", f"{total_time:.1f}ì´ˆ")
                
                # ì„±ëŠ¥ ë¶„ì„ (ì„ íƒì ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆê²Œ)
                with st.expander("ğŸš€ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„"):
                    # ì‹œê°ì  ë¹„ìœ¨ í‘œì‹œ
                    search_percent = (search_time / total_time) * 100
                    generation_percent = (generation_time / total_time) * 100
                    
                    st.write("**ì‹œê°„ ë¶„í¬:**")
                    st.progress(search_percent / 100)
                    st.caption(f"ê²€ìƒ‰: {search_percent:.1f}% ({search_time:.2f}ì´ˆ)")
                    
                    st.progress(generation_percent / 100)
                    st.caption(f"ë‹µë³€ ìƒì„±: {generation_percent:.1f}% ({generation_time:.2f}ì´ˆ)")
                    
                    # ì¶”ê°€ í†µê³„
                    if stats.get('category'):
                        st.write(f"**ê²€ìƒ‰ ìµœì í™”:** {stats['category']} ì¹´í…Œê³ ë¦¬ ìš°ì„  ê²€ìƒ‰")
                        st.write(f"**ê²€ìƒ‰ ë²”ìœ„:** {stats['primary_searched']}ê°œ / ì „ì²´ {stats['total_chunks']}ê°œ")
                    
                    # ì„±ëŠ¥ í‰ê°€
                    if total_time < 3:
                        st.success("âš¡ ë§¤ìš° ë¹ ë¥¸ ì‘ë‹µ!")
                    elif total_time < 5:
                        st.info("âœ… ì ì ˆí•œ ì‘ë‹µ ì†ë„")
                    else:
                        st.warning("â³ ì‘ë‹µì´ ë‹¤ì†Œ ëŠë ¸ìŠµë‹ˆë‹¤")
                
                # ì¶œì²˜ ì •ë³´ (ì ‘ì„ ìˆ˜ ìˆê²Œ)
                with st.expander("ğŸ“š ì°¸ê³  ìë£Œ ë³´ê¸°"):
                    for i, result in enumerate(results[:3]):
                        st.caption(f"**{result.source}** - í˜ì´ì§€ {result.page}")
                        st.text(result.content[:200] + "...")
                        st.divider()
                
                # ì„¸ì…˜ì— ì €ì¥ (ì‹œê°„ ì •ë³´ í¬í•¨)
                response_data = {
                    "content": answer,
                    "search_time": search_time,
                    "generation_time": generation_time,
                    "total_time": total_time,
                    "timestamp": time.time()
                }
                st.session_state.messages.append({"role": "assistant", "content": response_data})
    
    # í•˜ë‹¨ ì•ˆë‚´
    st.divider()
    st.caption("ğŸ’¡ ë³¸ ë‹µë³€ì€ AIê°€ ìƒì„±í•œ ì°¸ê³ ìë£Œì…ë‹ˆë‹¤. ì¤‘ìš”í•œ ì‚¬í•­ì€ ë°˜ë“œì‹œ ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    # ì˜ˆì‹œ ì§ˆë¬¸ (ì„ íƒì )
    with st.sidebar:
        st.header("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
        examples = [
            "ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜ ì´ì‚¬íšŒ ì˜ê²°ì€ ì–¸ì œ í•„ìš”í•œê°€ìš”?",
            "ë¹„ìƒì¥íšŒì‚¬ ì£¼ì‹ ì–‘ë„ ì‹œ ê³µì‹œ ì˜ë¬´ê°€ ìˆë‚˜ìš”?",
            "ê¸°ì—…ì§‘ë‹¨ í˜„í™©ê³µì‹œëŠ” ì–¸ì œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "íŠ¹ìˆ˜ê´€ê³„ì¸ì˜ ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ê³µì‹œ ì˜ë¬´ ìœ„ë°˜ ì‹œ ê³¼íƒœë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?"
        ]
        
        for example in examples:
            if st.button(example, key=example):
                st.session_state.prompt_input = example
                st.rerun()

if __name__ == "__main__":
    main()
